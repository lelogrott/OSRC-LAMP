\chapter{Reconhecimento de Faces}
\label{cap:reconhecimento_faces}

A capacidade humana de reconhecer faces se aprimora por meio do crescimento e longo dos anos. Estudos \cite{ingram04} mostram que bebês em seus primeiros dias de vida começam a desenvolver esta tarefa, se interessando na descoberta de rostos e seus movimentos. Crianças entre 6 e 8 anos possuem capacidade mais sofisticada, limitada entretanto por disfarces e adornos os quais as enganam facilmente. Já o reconhecimento em adultos é aperfeiçoado, exceto em caso de doenças que o impede ou dificulta como a prosopagnosia, incapacidade de identificação de faces. A facilidade de reconhecimento, porém, não se aplica a casos onde a face a ser reconhecida se encontra de cabeça para baixo, independente de idade ou doença. Além disso, apesar destas pesquisas apontarem a habilidade e evolução do reconhecimento facial, ainda não é possível explicar como esta tarefa ocorre, se por lembrança de características individuais ou do rosto como um todo.

Com base nisto, pesquisadores tentam desvendar as etapas realizadas pelo cérebro humano a fim de desenvolverem sistemas automáticos de reconhecimento de faces mais robustos. Em meados da década de 60 o primeiro sistema ainda semi automatizado foi proposto, utilizando características geométricas obtidas manualmente em cálculos relacionados a um ponto de referência. Este método evoluiu na década de 70 com a definição de marcadores principais para a realização dos cálculos, como espessura da boca e cor de cabelo. Somente no ano de 1991, com o surgimento de uma técnica de reconhecimento automatizado, permitiu-se a execução de sistemas de reconhecimento de faces em tempo real. Com isto, houve a disseminação e aumento no número de pesquisas nesta área, consequência presente nos dias atuais \cite{prates10}.

Algumas abordagens referentes à identificação de pessoas em imagens por meio da face são discutidas \cite{hirakuri03}, dentre elas o reconhecimento frontal estático e controlado, fornecedor da base deste trabalho. Neste contexto são consideradas faces em posição frontal, estáticas para a entrada ao sistema e em ambientes de iluminação controlada.

\citeonline{hirakuri03} identifica dois tipos de sistemas de reconhecimento: os sistemas que realizam tarefas de detecção e verificação (ou identificação) de faces em imagens são considerados completamente automáticos, diferentemente daqueles que efetuam apenas a tarefa de reconhecimento, estes denominados parcialmente automáticos. Neste trabalho será proposto um protótipo de sistema de reconhecimento facial parcialmente automático com base em um banco de imagens composto por retratos faciais controlados.

\section{Etapas de Reconhecimento de Faces}
\label{cap:etapas_reconhecimento_faces}

Uma tentativa de classificação dos passos necessários para efetuar por completo o reconhecimento de faces em imagens é proposta por \citeonline{prates10}. Este considera a etapa de detecção do rosto como primordial por meio da localização de faces em uma cena seguida da extração de características e posteriores cálculos e comparações, classificando a entrada como face pertencente ou não ao sistema e compondo assim a última etapa a ser executada. Esta abordagem entretanto é genérica, apresentando possibilidade de divisão se considerada apenas a ação de detecção ou reconhecimento, ou tomada por inteiro, quando tratadas em conjunto pelo sistema.

\citeonline{pradojunior05} sugere outra classificação. O autor enfatiza apenas o reconhecimento de faces, não levando em consideração a detecção das mesmas em imagens ou vídeo e tomando como entrada um retrato contendo uma face frontal, realizando a divisão conforme abaixo:

\begin{itemize}
	\item A primeira etapa é a de pré-processamento, na qual ruídos e interferências são minimizadas ou removidas por completo da imagem.
	\item Algumas técnicas, citadas e explicadas posteriormente, utilizam a extração de atributos como distâncias de olhos ou tamanho da boca, servindo de entrada para cálculos e métodos propostos.
	\item Por fim são comparados os atributos obtidos pelo método desenvolvido e a base de dados, habilitando ou não a entrada do usuário pelo sistema.
\end{itemize}

Estas abordagens demonstram o funcionamento de um sistema de reconhecimento de faces e servem como base para quem procura desenvolver e aprimorar sistemas nesta área. Em um contexto geral, um sistema de reconhecimento de faces pode ser representado conforme a figura \ref{fig:sistema_rec_facial_generico}. De acordo com a figura, uma imagem de entrada é apresentada ao sistema, suas características são extraídas e representadas em uma estrutura de dados (no caso um vetor), e sua classificação é gerada a partir de imagens de treinamento $E_{Q}$.

\begin{figure}[ht]
\centering
\caption{Sistema genérico de reconhecimento de faces.}
\includegraphics[scale=0.50]{imagens/figura2.png} \\
Fonte: \citeonline{marin06}.
\label{fig:sistema_rec_facial_generico}
\end{figure}

\section{Abordagens de reconhecimento de faces}

As técnicas de reconhecimento facial podem ser subdivididas em grupos de acordo com sua forma de tratar e extrair as características desejadas. Segundo \citeonline{mendonca08}, os grupos podem ser definidos conforme a seguir:

\begin{itemize}
	\item Métodos holísticos: a face é utilizada como um todo pelo sistema de reconhecimento.
	\item Métodos baseados em características locais: extrai características locais como olhos, nariz e boca para posterior classificação por meio de suas posições e geometria.
	\item Métodos híbridos: utiliza as duas abordagens anteriores para realizar o reconhecimento, assim como o sistema de percepção humano.
\end{itemize}

De acordo com o grupo ao qual o sistema de reconhecimento pertença, algumas abordagens podem ser utilizadas para tratar as características desejadas. Casamento de modelos ({\it template matching}), métodos estatísticos, análise estrutural sintática e redes neurais são as mais relevantes.

\subsection{Casamento de Modelos ({\it Template Matching})}
A mais antiga e também mais simples abordagem de reconhecimento de padrões é o casamento de modelos. Esta se baseia no processo de comparação de similaridade entre duas entidades do mesmo tipo, constituídas por pontos, curvas ou formas geométricas. Assim, em reconhecimento de faces essas entidades são os próprios rostos de pessoas as quais se deseja identificar \cite{dasilva06}.

As principais variações na estrutura (rotação, translação, escala e rotação) dos modelos são consideradas durante a etapa de comparação entre dois padrões. Em casos onde o padrão armazenado não é adaptado a deformações que podem ocorrer na entrada, modelos deformáveis podem ser considerados para solução do problema \cite{matos03}.

Esta abordagem, apesar da simplicidade, apresenta desvantagens em relação ao alto custo computacional exigido \cite{dasilva06}.

\subsection{Abordagem Estatística}

O uso de métodos estatísticos em reconhecimento facial é um subgrupo pertencente à abordagem estatística de reconhecimento de padrões. De acordo com \citeonline{matos03}, um sistema de reconhecimento de padrões estatístico pode ser formado pelas seguintes partes: um sistema de aquisição de dados (câmera ou sensor, por exemplo), pré-processamento para eliminação de ruídos ou distorções, extrator de características (ou atributos) para a criação de um vetor de características e redução de dados extraídos dos objetos adquiridos em atributos, propriedades ou características, um seletor de características o qual analisa e seleciona as mais relevantes, além de um classificador que analisa o padrão obtido e toma uma decisão.

Assim, um padrão é considerado como um vetor de d {\it features} ou características, pertencendo a um espaço d-dimensional. Conforme definição na seção 2.4, uma classe abrange os padrões que possuem alguma relação. \citeonline{morais10} demonstra como esta forma de classificação poderia ser aplicada em um exemplo simples de sistema biométrico: considerando um espaço de características $X$ na qual $x_{1}$ representasse altura, $x_{2}$ o peso e $x_{3}$ o tamanho dos pés, cada instância de $X$ representaria as medições de uma pessoa em determinado momento, na qual cada classe representaria uma família de pessoas. Para um problema como este, a classificação seria definida pela obtenção do vetor de características de uma pessoa e determinação da família a qual provavelmente essa pessoa pertence.

Em reconhecimento de faces, esta abordagem é tratada por meio da representação de cada face por um vetor de pesos. Quando uma nova imagem de entrada é apresentada ao sistema para realizar a identificação ou verificação com o banco de imagens seu vetor de características é obtido e posteriormente comparado ao dados do banco \cite{zhao03}.

O nome ``abordagem estatística'' se origina pela classificação de um padrão ser realizada de acordo com estimativas probabilísticas dos dados obtidos. \citeonline{marin06} relata como vantagens desta abordagem a eficiência e o melhor tratamento de entradas com ruído ou interferência. Por outro lado, há limitação quanto a sistemas que necessitam de informações estruturais importantes além de um número elevado de padrões de entrada serem necessários ao projeto de um classificador.

\subsection{Análise Estrutural Sintática}

Por meio da análise de um padrão é possível visualizar uma estrutura interna hierárquica que o compõe. Ou seja, dentro de um padrão mais complexo são obtidos padrões mais simples. Desta forma, os métodos estruturais sintáticos utilizam a estrutura interna do padrão para análise e comparação \cite{dasilva06}.

\citeonline{friedlaender03} divide o reconhecimento de padrões estrutural sintático em duas partes: análise e reconhecimento. Na etapa de análise são extraídas as informações estruturais mais importantes do padrão por meio da seleção de primitivas (contornos ou regiões) para a fase posterior de reconhecimento. Portanto, ao contrário da abordagem estatística que utiliza um vetor para representação das características, estruturas de maior complexidade como gráficos são utilizadas por esta abordagem.

Desvantagens da análise estrutural sintática se encontram na necessidade de separação de ruídos para a segmentação de padrões e um esforço computacional elevado na busca destes \cite{matos03}.

\subsection{Redes Neurais}

Pesquisas sobre redes neurais são motivadas pela forma que o cérebro humano processa informações. Os neurônios, partes constituintes do cérebro, são comparados a pequenas unidades de processamento os quais, em conexão, realizam tarefas como reconhecimento de padrões \cite{haykin01}.

Segundo \citeonline{fukushima88}, esta abordagem trata uma rede por meio de aprendizado, na qual pesos são atribuídos a cada conexão e estas ligações crescem gradualmente de acordo com os estímulos fornecidos à rede. Assim, a classificação dos padrões de entrada ocorre de maneira automática, sem a necessidade de categorização anterior à aprendizagem. Quando inseridas novas entradas, cada padrão será reconhecido separadamente, sem a obrigatoriedade em relação aos padrões de entrada com os padrões aprendidos pela rede serem idênticos.

\citeonline{hugo95} relata as principais vantagens da abordagem de redes neurais em reconhecimento de padrões:

\begin{itemize}
	\item Adaptabilidade a novas informações.
	\item Velocidade de reconhecimento pelo uso de camadas de neurônios paralelamente.
	\item Tolerância a falhas, fornecendo capacidade de reconhecimento na presença de ruídos e interferências.
	\item Taxas de erros otimizadas em sistemas de classificação.
\end{itemize}	

As redes neurais mais utilizadas para o reconhecimento de padrões são as redes diretas as quais incluem perceptron e redes função base radial (BRF ou RBF) por exemplo, organizadas em camadas com conexão unidirecional entre as mesmas, além de mapa auto organizável (SOM) e rede de Kohonen, estas com características de aglomeração de dados e mapeamento de características. Estas redes fornecem algoritmos não lineares de extração de características e classificação \cite{marin06}.

Tendo em vista as abordagens citadas, uma análise comparativa entre as três últimas estudadas é apresentada na tabela \ref{abordagens}, apontando o modo de organização das características e as principais limitações de cada abordagem.

\begin{table}[ht]
\centering
\caption{Tabela comparativa das principais abordagens de reconhecimento facial.}
\begin{tabular}{|p{3.5cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|} \hline
 & A. Estatística & A. Sintática & A. Neural \\ \hline
Base de Geração de Padrão & Modelos Probabilísticos & Gramáticas formais & Estados estáveis ou vetor de pesos \\ \hline
Organização de características & Vetor de características & Primitivas e relações observadas & Entradas neurais ou estados armazenados \\ \hline
Limitações & Dificuldade em expressar informações estruturais & Dificuldade em aprender regras estruturais & Pouca informação semântica da rede \\ \hline
\end{tabular} \\
Fonte: Tabela adaptada de \citeonline{marin03}.
\label{abordagens}
\end{table}

\section{Principais técnicas de reconhecimento de faces}

Nesta seção as principais técnicas de reconhecimento de faces serão discutidas, apresentando a forma de desenvolvimento e as etapas seguidas por cada método.  

\subsection{Análise de Componentes Principais (PCA)}

Os métodos holísticos caracterizam-se pela utilização de todos os pixels da imagem para realização do reconhecimento, apresentando portanto uma alta dimensionalidade da entrada. Técnicas estatísticas podem reduzir a dimensão da imagem a fim de melhorar o desempenho. Um exemplo de método estatístico é a Análise de Componentes Principais (em inglês, Principal Component Analysis - PCA) \cite{lata09}.

Segundo \citeonline{moon01} algoritmos baseados em PCA foram os primeiros a surgir na área de reconhecimento de faces, com vantagens na facilidade de implementação e razoável desempenho. Na figura \ref{fig:pca} um esquema geral dos passos seguidos pelo método PCA é sugerido. Inicialmente é definido um grupo de imagens de treinamento e uma imagem teste gerando as {\it eigenfaces} e posteriormente é calculada a distância euclidiana entre a imagem teste e as imagens de treinamento pós processadas. Assumindo um valor limite, o objetivo é encontrar a menor distância a fim de determinar a respectiva face de treinamento para a face de entrada.

\begin{figure}[ht]
\centering
\caption{Esquema geral da técnica de Análise de Componentes Principais.}
\includegraphics[scale=1.0]{imagens/figura5.png} \\
Fonte: Imagem adaptada de \citeonline{menezes09}.
\label{fig:pca}
\end{figure}

Nesta técnica, a busca pela redução da dimensionalidade da entrada é obtida por meio da criação de um espaço de características a partir do espaço de dados (imagem). Sua resolução sofre mudanças pela redução das características efetivamente consideradas, preservando porém a estrutura global da imagem \cite{wang10}. Para isto, é necessária a construção matemática dos vetores de características ({\it eigenfaces}) a partir das imagens de treinamento, conforme definido a seguir \cite{cruz11}.

Considerando a representação de uma imagem em níveis de cinza por uma matriz bidimensional e admitindo $X$ como um conjunto de vetores compostos pela concatenação de linhas dos dados da imagem de treinamento de tamanho $M$ $\times$ $N$ ($O$ = $M$ $\times$ $N$), é possível definir um vetor $m$ com a média dos $r$ vetores do conjunto $X$:

\begin{equation}
m = \frac{1}{r} \sum_{j=1}^{r}X_{j}
\end{equation}

Desta forma, é obtido um conjunto modificado $A = \{d_{1}, d_{2}, ..., d_{r}\}$ de $X$ por meio da subtração de seus elementos (vetores) pelo vetor média:

\begin{equation}
d_{j} = X_{j} - m
\end{equation}

Esta etapa serve para identificar as características de cada face divergente das outras. As {\it eigenfaces} então geradas podem ser vistas na figura \ref{fig:eigenfaces}. A partir disto, calcula-se a matriz de covariância ($C$) para o conjunto $d_{j}$ a partir do conjunto de faces subtraídas da média:

\begin{figure}[ht]
\centering
\caption{Imagens de entrada e suas respectivas {\it eigenfaces}.}
\includegraphics[scale=0.78]{imagens/figura6.png} \\
Fonte: \citeonline{lopes05}.
\label{fig:eigenfaces}
\end{figure}

\begin{equation}
C = \frac{1}{r} \sum_{j=1}^{r}d_{j}d_{j}^T
\end{equation}

Ou seja, a matriz de covariância $C$ é $\frac{AA^{t}}{r}$. Contudo, esta matriz tem seu tamanho ($O$ $\times$ $O$) computacionalmente inviável, tornando o problema de determinar {\it eigenvectors} e {\it eigenvalues} \cite{bortolini10} intratável. Como exemplo, a partir de imagens de entrada em dimensões 256 $\times$ 256, a matriz de covariância obtida apresenta tamanho 65536 $\times$ 65536 \cite{cruz11}.

Para solucionar este problema, o método PCA determina a criação de uma matriz $P$ composta pelos autovetores ligados aos maiores autovalores da matriz de covariância. Neste processo, a dimensão da matriz passa de $O$ $\times$ $O$ para $r$ $\times$ $r$.

Para cada imagem de treinamento ($I_{i}$) é calculado um vetor de pesos ($W_{iK}$) que será utilizado na classificação das demais imagens de entrada:

\begin{equation}
W_{iK} = E_{K}^{T} \cdot (I_{i} - A) \textrm{ para todo }i,K
\end{equation}

onde $E_{K}$ representa a matriz $P$. Quando uma nova imagem é apresentada ao sistema e projetada no espaço de faces ({\it eigenspace}), a mesma fórmula é utilizada:

\begin{equation}
W_{test K} = E_{K}^{T} \cdot (I_{test} - A) \textrm{ para todo }K
\end{equation}

O vetor $W_{test K}$ representa o vetor de pesos da imagem utilizado para predefinir a classe a qual a entrada pertence, e $I_{test}$ a imagem de entrada.

Uma imagem de teste pode ser classificada em determinada classe quando a diferença entre o vetor de pesos encontrado a ela e o vetor médio desta classe for menor que um limiar (valor limite) previamente definido \cite{gottumukkal04}.

\subsection{Análise de Discriminante Linear (LDA)}

A análise de discriminante linear (em inglês, {\it linear discriminant analysis} - LDA) foi desenvolvida por 
Robert Fisher em 1936. Também conhecida como técnica {\it fisherface}, procura classificar as faces maximizando a variância entre classes e minimizando a variância intraclasse, garantindo a máxima separação entre as classes de um conjunto de dados \cite{chelali09}.

Segundo \citeonline{santos11}, LDA utiliza dos mesmos princípios propostos pelo método {\it eigenface}, ou seja, apresenta imagens de entrada vetorizadas, cálculo de matriz de covariância e redução de dimensionalidade da imagem de entrada. 

Duas fases principais são consideradas nesta técnica: treinamento e classificação. Na fase de treinamento, um espaço de projeção denominado {\it Fisher Space} é criado a partir das imagens de treinamento, sendo estas projetadas sobre o mesmo subespaço. Nesta fase pode ser utilizada a matriz de saída de algoritmos baseados em PCA. Na fase de classificação uma face de entrada é projetada no Fisher Space e classificada segundo semelhança com base no cálculo de distância euclidiana \cite{chelali09}.

Em termos matemáticos, o algoritmo LDA realiza os seguintes passos \cite{melisek08}:

\begin{enumerate}
	\item Cálculo da matriz de espalhamento intraclasse segundo as fórmulas
		\begin{equation}
			S_{w} = \sum_{i=1}^{C} \frac{1}{C} S_{i}
		\end{equation}
		\begin{equation}
			S_{i} = \sum_{x \in X_{i}} (x-m_{i}) (x-m_{i})^{T}
		\end{equation}
		na qual $m_{i}$ é a média das imagens da classe, $C$ o número de classes e 1/C é a probabilidade de cada uma.
		Para calcular a matriz de espalhamento entre classes a seguinte fórmula é utilizada
		\begin{equation}
			S_{B} = \sum_{i=1}^{C} \frac {1}{C} n_{i}(m_{i} - m) (m_{i} - m)^{T}
		\end{equation}
		onde $n_{i}$ é o número de imagens na classe e $m$ a média de todas as imagens:
		\begin{equation}
			m = \frac{1}{C} \sum_{i=1}^{C} m_{i}
		\end{equation}
	\item O vetor discriminante ($W_{opt}$) que maximiza a variância entre classes e minimiza a variância intra classe é calculado:
		\begin{equation}
			W_{opt} = \textrm{arg max } \left|\frac {W^{T}S_{B}W}{W^{T}S_{w}W}\right|
		\end{equation}
		\begin{equation}
			W_{opt} = [w_{1} w_{2} \cdots w_{n}]	
		\end{equation}
		sendo $w_{i}$ o conjunto de autovetores generalizados e $n$ o número dos maiores autovalores escolhidos.
	\item Para encontrar a melhor projeção do vetor $W$ \cite{santos11} é necessário resolver o problema de autovalores generalizados
		\begin{equation}
			S_{B} W = S_{w} W \Lambda
		\end{equation}
		na qual $\Lambda$ é o conjunto dos $n$ autovalores escolhidos, obtidos em $S_{w}^{-1} \cdot S_{b}$ e os autovetores são definidos pela multiplicação destas matrizes.
\end{enumerate}

Após a projeção das imagens de teste no subespaço e na ocorrência de um nova imagem apresentada ao sistema é calculada a diferença da face de entrada com a média obtida ($m$) e definida a distância euclidiana para cada classe conhecida. A imagem de entrada é classificada de acordo com a menor distância euclidiana verificada \cite{chelali09}.

\begin{equation}
	d_{e} = ||\Omega - \Omega_{c}||
\end{equation}

Nesta equação, $\Omega$ representa o vetor da classe e $\Omega_{c}$ o vetor da diferença da imagem de entrada pela média ($m$).

Vantagens da técnica {\it fisherface} são apresentadas por \citeonline{zhao98}: boa classificação quando as características da face de entrada são linearmente separáveis e simplicidade de implementação, necessária quando a complexidade computacional é elevada.

\subsection{Support Vector Machines (SVM)}
\label{svm}

Support Vector Machines (SVM) são sistemas de aprendizagem de máquina, ou seja, por meio de imagens de exemplo é possivel construir um classificador que auxilie no reconhecimento de padrões realizado após treinamento. Baseada na teoria de aprendizagem estatística, esta técnica classifica por meios matemáticos padrões não treinados, característica esta denominada generalização. Divide-se o aprendizado de máquina em duas definições principais: o supervisionado, com classes pré-definidas pelo analista, e o não-supervisionado, no qual o algoritmo identifica as classes existentes num conjunto de dados \cite{andreola09}. Uma idéia de funcionamento do aprendizado de máquina (AM) supervisionado pode ser visualizada na figura \ref{fig:svm_supervisionado}, apresentando um conjunto de treinamento a uma técnica de AM e gerando um classificador $f(x)$. 

\begin{figure}[h]
    \centering
	\caption{Indução de classificador em aprendizado supervisionado.}
    \includegraphics[scale=0.6]{imagens/figura7.png} \\
    Fonte: \citeonline{lorena07}.
    \label{fig:svm_supervisionado}
\end{figure}

SVM aplicado ao reconhecimento de faces tem por objetivo separar as faces de treinamento em duas classes principais por meio de funções lineares. Em casos em que a divisão em um maior número de classes for necessária, funções não-lineares (polinômios por exemplo) são aplicadas às imagens de treinamento.

O objetivo deste método portanto, é encontrar o hiperplano divisor de classes mais eficiente, classificando-as de acordo com a definição da maior margem de separação entre classes conforme a figura \ref{fig:svm}. Tratando matematicamente o método é possível definir as principais características de um sistema baseado em SVM supervisionado conforme descrito a seguir \cite{lorena07}.

\begin{figure}[ht]
    \centering
	\caption{Melhor classificação linear em SVM de duas classes.}
    \includegraphics[scale=0.50]{imagens/figura8.png} \\
    Fonte: \citeonline{luo05}.
    \label{fig:svm}
\end{figure}

Considerando uma matriz composta por $n$ faces, cada qual representada por uma linha da matriz ($x_{n}$), sendo $x_{n} = (x_{1}, x_{2}, \cdots, x_{m})$ na qual $m$ é o número de atributos (características) da imagem e a última coluna($y_{n}$) a classe a qual a face de treinamento pertence, é possível aplicar esta entrada a um algoritmo de aprendizado de máquina que selecionará um classificador conforme a figura \cite{lorena07}.

Seja $F$ um conjunto de todos os classificadores que um determinado algoritmo de aprendizado de máquina pode adotar, gera-se um classificador específico $f$ para um conjunto de treinamento ($T$) composto de pares ($x_{i}$,$y_{i}$). O classificador ideal é capaz de separar a maior parte dos dados corretamente, não se preocupando em agrupar todas as imagens sem ocorrência de erros. A classificação por meio de $f$, porém, apresenta riscos de ocorrer erroneamente. Este risco é calculado por meio de fórmulas considerando probabilidades estimadas inicialmente desconhecidas e equações que retornam se a entrada foi classificada corretamente.

Assim, considerando $w_{i}$ o vetor normal ao hiperplano que separa duas classes e $\frac {b}{||w||}$ a distância do hiperplano à origem, tem-se:

\begin{equation}
f(x) = w \cdot x + b = 0
\end{equation} 

sendo $w \cdot x$ definidor por

\begin{equation}
w \cdot x = \sum_{i=1}^{n} w_{i}x_{i}
\end{equation}

Esta fórmula permite a divisão dos dados $x_{i}$ em duas regiões, classificadas a partir do sistema:

\begin{equation}
class(x_{i}) = 
\left\{
\begin{array}{ll}
\displaystyle +1 \textrm{ se } w \cdot x_{i} + b > 0 \\
\displaystyle -1 \textrm{ se } w \cdot x_{i} + b < 0
\end{array}
\right.
\end{equation}

Então, tomando $x_{1}$ como um ponto pertencente ao hiperplano $H_{1}$ e $x_{2}$ um ponto pertencente ao hiperplano $H_{2}$, obtem-se a distância euclidiana entre os dois pontos por meio de suas projeções perpendiculares ao hiperplano separador $w \cdot x + b = 0$.

Desenvolvendo o sistema anterior \cite{ivanciuc07}, é possível obter a equação

\begin{equation}
||x_{1} - x_{2}|| = \frac {1}{||w||}
\end{equation}

que representa a distância entre os hiperplanos $H_{1}$ e $H_{2}$. Ou seja, para maximizar a distância entre os hiperplanos, é necessário minimizar o valor de $w$. Este cálculo é desenvolvido em \citeonline{ivanciuc07} por meio da função de Lagrange \cite{ferrario08} e apresenta como resultado os vetores de suporte (em inglês, {\it Support Vectors} - SV), considerados os dados mais informativos do conjunto de treinamento que participam na determinação da equação do hiperplano separador e o limiar $b$, obtido pela média de valores dos vetores de suporte. Com isto, a margem entre os hiperplanos é maximizada e as classes melhor separadas.

Aplicando esta técnica ao problema de reconhecimento de faces as classes obtidas pelo método representam, isoladamente, as próprias faces. A distinção e a classificação são definidas pelas variações das características faciais, determinadas anteriormente por outra técnica (PCA, por exemplo) ou manualmente \cite{phillips99}. Ou seja, este método utiliza outras técnicas (algumas estudadas neste trabalho) para a criação do descritor das características faciais utilizadas no reconhecimento e assim realizar a correta classificação da entrada.

\subsection{Speeded-Up Robust Feature (SURF)}
\label{surf}

Os métodos de reconhecimento de faces já apresentados, largamente utilizados e revisados na literatura, demonstram certa limitação em questões de posição e iluminação das imagens de entrada ao sistema. O método SURF ({\it Speeded-Up Robust Feature}), inspirado no método SIFT ({\it Scale Invariant Feature Transform}), surge como uma forma de contornar grande parte dos problemas enfrentados pelas técnicas anteriormente discutidas. Enquanto SIFT utiliza o filtro gaussiano para detectar os pontos de interesse, SURF faz uso de {\it Hessian Matrix} sobre a imagem integral, reduzindo assim o tempo computacional do algoritmo e o tamanho final dos descritores \cite{shan09}.
	
Criada em 2006 por Herbert Bay \cite{bay06}, SURF baseia-se na transformação de uma imagem em um conjunto de descritores (vetores) de características ou pontos de interesse, estes invariantes à translação, escala e rotação, e parcialmente invariantes a mudanças de iluminação. Além disso, é robusta em relação a ruídos e distorções geométricas locais. Nesta técnica, a correspondência entre duas faces, uma padrão ao sistema e outra de teste, é obtida pela comparação entre os descritores locais das duas imagens \cite{dreuw09}.

\citeonline{hasa11} relata a divisão da técnica SURF em duas etapas principais: detecção e descrição. Na detecção os pontos de interesse da imagem são localizados e posteriormente representados pelo descritor por meio da construção de vetores de características.

\subsubsection{Detecção de Pontos de Interesse}
\label{dpisurf}

A tarefa de detectar os pontos de interesse de uma imagem pode ser iniciada com o cálculo da imagem integral da entrada para diminuir o tempo de processamento das próximas etapas do algoritmo \cite{bay08}. Determinando a imagem integral, para todo ponto $d$ ($x_{i}$, $y_{j}$) da imagem são somados todos os valores menores que $x_{i}$ e $y_{i}$. Ou seja, a partir do ponto $d$ são somados os valores pertencentes ao retângulo existente entre a origem e $d$:

\begin{equation}
I_{e}(x) = \sum_{i=0}^{i<=x_{i}} \sum_{j=0}^{j<=y_{i}} I(i,j)
\end{equation}

Na determinação dos pontos de interesse, uma aproximação da matriz Hessiana (em inglês, {\it Hessian Matrix}) é definida a partir do sistema \cite{du09}:

\begin{equation}
H(x, \sigma) = \left[\begin{array}{rrr}
L_{xx}(d,\sigma) & L_{xy}(d, \sigma) \\
L_{xy}(d,\sigma) & L_{yy}(d,\sigma) \end{array} \right]
\end{equation}

na qual $d$ é um ponto da imagem definido na escala $\sigma$, e $L_{xx}$, $ L_{xy}$ e $L_{yy}$ são as convulações das derivadas parciais de segunda ordem de Gauss para aquele ponto. Para reduzir o tempo computacional gasto nas convoluções, filtros de caixa são utilizados como aproximação da Gaussiana e define-se $\sigma=1.2$ para representação da menor escala a fim de construir o mapa estrutural da entrada.

Para representar a aproximação Gaussiana, apresentada na figura \ref{fig:aprox_gauss}, são definidos $D_{yy}$, $D_{xy}$ e $D_{xx}$ relacionados a $L_{yy}$, $L_{xy}$ e $L_{xx}$, respectivamente. Esta alteração aplicada à matriz hessiana para o cálculo do determinante resulta em:

\begin{equation}
det(H_{aprox}) = D_{xx}D_{yy} - (wD_{xy})^{2}
\end{equation} 

sendo $w$ um peso necessário para conservação de energia entre a função Gaussiana e sua aproximação (no caso, filtros de caixa).

\begin{figure}[ht]
    \centering
	\caption{Da esquerda para a direita, derivadas parciais gaussianas de segunda ordem nas direções $y$ e $xy$ e suas aproximações em iguais direções.}
    \includegraphics[scale=0.60]{imagens/figura9.png} \\
    Fonte: \citeonline{bay08}.
    \label{fig:aprox_gauss}
\end{figure}

A matriz hessiana aproximada é determinada para todo ponto $x$ pertencente à imagem de entrada, formando assim um mapa estrutural composto pelos determinantes de cada pixel da entrada. 

A próxima etapa da técnica consiste em aumentar a escala do filtro aplicado à entrada e subamostrar a imagem processada. No método SIFT, como cada camada depende da anterior, é necessário redimensionar a imagem a cada etapa, aumentando o tempo computacional gasto. Como no método SURF o tempo de processamento para cada filtragem não varia, isso permite o processamento de múltiplas escalas simultaneamente, eliminando a necessidade de subamostrar as imagens e aumentando o desempenho do algoritmo.

Na determinação dos pontos de intesse, para cada três imagens graduais filtradas são criadas janelas 3 $\times$ 3. Com isto, define-se o valor máximo das três janelas e é atribuido valor zero (cor preta) aos {\it pixels} de valor menor ao máximo. Esta etapa pode ser vista na figura \ref{fig:extremos_surf}.

\begin{figure}[ht]
    \centering
	\caption{Detecção de extremos no espaço-escala.}
    \includegraphics[scale=0.60]{imagens/figura10.png} \\
    Fonte: \citeonline{gonzales11}.
    \label{fig:extremos_surf}
\end{figure}

\subsubsection{Descrição de Pontos de Interesse}

O método SURF propõe a construção de regiões circulares ao redor dos pontos de interesse. Com base na sua orientação é determinada a orientação dominante do ponto de interesse, garantindo assim a invariância na rotação da imagem apresentada ao sistema. Esta orientação é obtida por meio da transformada de Haar (em inglês, {\it Haar Wavelet}) nas direções $x$ e $y$, incluindo às informações do ponto de interesse a orientação calculada. Os descritores são então extraídos pela construção de regiões quadradas ao redor do ponto, estas separadas em subregiões descritas por vetores de quatro dimensões com as intensidades de cada subregião.

Quando uma nova imagem é apresentada ao sistema, é necessário definir os pontos de interesse e descritores desta e extrair os pontos em comum entre ela e sua correspondência no banco de dados. Isto é alcançado pela pesquisa do vizinho mais próximo por meio da distância euclidiana entre um vetor descritor da imagem de treinamento e um vetor da imagem de entrada ao sistema. Um exemplo é apresentado na figura \ref{fig:exemplo_surf}.

\begin{figure}[ht]
	\centering
	\caption{Resultado da técnica SURF. (a) Pontos de interesse. (b) Distância euclidiana.}
    \subfigure[]{
        \includegraphics[width=0.5\hsize]{imagens/figura11a.png}
    }
    \hspace{2mm}
    \subfigure[]{
         \includegraphics[width=0.5\hsize]{imagens/figura11b.png}
    } \\
	Fonte: \citeonline{du09}.
   \label{fig:exemplo_surf}
\end{figure}

\section{Problemas detectados}

Considerando que sistemas de reconhecimento de faces implementados recebem como entrada fotos ou vídeos, alguns problemas detectados nas entradas podem interferir no correto reconhecimento. \citeonline{coutinho07} relata os principais: iluminação do ambiente e posição da face. 

Em ambientes com pouca iluminação ou muito brilho as características de faces utilizadas no reconhecimento são prejudicadas pela dificuldade em extraí-las e descrevê-las, visto que suas propriedades podem ser confundidas ou sobrepostas pela falta ou excesso de iluminação. Como descrito pelo autor, alguns algoritmos de reconhecimento de faces são adaptados a dificuldades de iluminação acrescentando etapas de processamento à imagem de entrada.

O segundo problema citado pode ser corrigido por alterações bidimensionais de rotação, a fim de efetuar o alinhamento das faces aos eixos, ou normalizações tridimensionais conforme descrito pelo autor.

Estes dois problemas, os principais relatados, são melhor tratados pelo método SURF, o qual demonstra contornar ruídos e transformações simples na imagem de entrada e apresenta resultado de reconhecimento de faces satisfatório \cite{du09}.

Algumas aplicações para sistemas de reconhecimento de faces e suas principais vantagens e desvantagens são apresentadas na tabela \ref{fig:aplica_vant_desvant}. Pode-se observar que uma característica vantajosa a uma aplicação pode não ter o mesmo efeito em outra, principalmente pela forma de entrada a cada sistema. Como exemplo o uso de cartão de créditos ou passaporte utiliza imagem de qualidade e controlada o que facilita a segmentação, enquanto em aplicações de vigilância a imagem é de baixa qualidade e difícil de ser segmentada. 

\begin{table}[ht]
\centering
\caption{Exemplos de aplicações de reconhecimento de faces e suas principais vantagens e desvantagens.}
\begin{tabular}{|p{5cm}|p{5cm}|p{5cm}|} \hline
Aplicações & Vantagens & Desvantagens \\ \hline
Cartões de crédito, licença de motorista, passaporte e identificação pessoal  & Imagem controlada, segmentação controlada e boa qualidade nas imagens & Não existe banco de dados grande, dificuldade na busca quando o banco de dados aumenta\\ \hline
Retrato falado & Imagem padronizada e mais de uma imagem disponível & Não existe banco de dados grande, dificuldade na busca quando o banco de dados aumenta \\ \hline
Segurança em bancos/lojas & Localização geográfica conhecida & Segmentação não-controlada e baixa qualidade nas imagens \\ \hline
Vigilância em locais públicos & Sistemas de câmeras instalados (Shopping, Praça, ...) & Segmentação não-controlada, baixa qualidade nas imagens e processamento em tempo real \\ \hline
Identificação inteligente & Mercado em expansão & Baixa qualidade nas imagens \\ \hline
\end{tabular} \\
Fonte: \citeonline{santos11}.
\label{fig:aplica_vant_desvant}
\end{table}
